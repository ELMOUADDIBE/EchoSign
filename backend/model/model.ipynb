{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ! pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 87000 files [33:33, 43.21 files/s]\n"
     ]
    }
   ],
   "source": [
    "# import splitfolders\n",
    "# train_src = \"./dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "# splitfolders.ratio(train_src, output=\"datasets/asl_alphabet\",\n",
    "#     seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tenforflow\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datasets/asl_alphabet/train'\n",
    "val_dir = 'datasets/asl_alphabet/val'\n",
    "test_dir  = 'datasets/asl_alphabet/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "batch_size = 32\n",
    "target_size = (32,32) # dataset pic = 200x200\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_generator.class_indices.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = train_dir\n",
    "def sample_images(labels):\n",
    "    # Create Subplots\n",
    "    y_size = 12\n",
    "    if(len(labels)<10):\n",
    "        y_size = y_size * len(labels) / 10\n",
    "    fig, axs = plt.subplots(len(labels), 9, figsize=(y_size, 13))\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        axs[i, 0].text(0.5, 0.5, label, ha='center', va='center', fontsize=8)\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        label_path = os.path.join(TRAIN_PATH, label)\n",
    "        list_files = os.listdir(label_path)\n",
    "\n",
    "        for j in range(8):\n",
    "            img_label = cv2.imread(os.path.join(label_path, list_files[j]))\n",
    "            img_label = cv2.cvtColor(img_label, cv2.COLOR_BGR2RGB)\n",
    "            axs[i, j+1].imshow(img_label)\n",
    "            axs[i, j+1].axis(\"off\")\n",
    "\n",
    "    # Title\n",
    "    plt.suptitle(\"Sample Images in ASL Alphabet Dataset\", x=0.55, y=0.92)\n",
    "\n",
    "    # Show\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)\n",
    "input_shape = (32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = models.Sequential()\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 2nd convolution layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd convolution layer\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# fully-connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define checkpoint path\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_generator) \n",
    "print('Test loss: ', scores[0])\n",
    "print('Test accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des scores\n",
    "test_loss = scores[0]\n",
    "test_accuracy = scores[1]\n",
    "\n",
    "# Création de la figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Données pour le graphique\n",
    "metrics = ['Loss', 'Accuracy']\n",
    "values = [test_loss, test_accuracy]\n",
    "\n",
    "# Création du bar plot\n",
    "ax.bar(metrics, values, color=['blue', 'green'])\n",
    "\n",
    "# Titre et étiquettes\n",
    "ax.set_title('Test Loss and Accuracy')\n",
    "ax.set_ylabel('Values')\n",
    "\n",
    "# Affichage des valeurs sur les barres\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(i, v + 0.02, str(v), ha='center', va='bottom')\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.ylim(0, 1.2)  # Ajustez cette ligne en fonction de vos valeurs pour une meilleure visualisation\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"asl_alphabet_cnn.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
